{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8f1777-ae23-4edc-82da-8ac6754af98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454a915d-25f1-4ca5-820f-8b9076f79d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--cheat-init'], dest='cheat_init', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='initializae the network with direction of the data', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "    \n",
    "argparser = argparse.ArgumentParser()\n",
    "##argparser.add_argument('-d','--input_size', type=int, default=28*28, help='model name')\n",
    "argparser.add_argument('-n','--hidden_size', type=int, default=8192, help='hidden size')\n",
    "\n",
    "\n",
    "argparser.add_argument('-r','--range', type=float, default=10.0, help='set the range of the input data')\n",
    "argparser.add_argument('-N','--num-samples', type=int, default=32, help='set the number of the input data centers')\n",
    "argparser.add_argument('-a','--alpha', type=float, default=90, help='detenrmine the angle between close input data points')\n",
    "argparser.add_argument('-s','--sigma', type=float, default=0.05, help='noise level')\n",
    "\n",
    "argparser.add_argument('-S','--seed', type=int, default=0, help='set the random seed')\n",
    "argparser.add_argument('-D','--device', type=int, default=0, help='set the device')\n",
    "\n",
    "argparser.add_argument('-x','--dist', type=int, default=1.0, help='set the distance between the two neighbouring input data points')\n",
    "\n",
    "argparser.add_argument('--lr', type=float, default=0.1, help='learning rate')\n",
    "argparser.add_argument('--wd', type=float, default=0.1, help='weight decay')\n",
    "argparser.add_argument('-b','--batch-size', type=int, default=(64*3), help='batch size')\n",
    "argparser.add_argument('-E','--epochs', type=int, default=1000, help='epochs')\n",
    "\n",
    "argparser.add_argument('--misc', action='store_true', default=False, help='miscellaneous')\n",
    "\n",
    "argparser.add_argument('-o','--obtuse', action='store_true', default=False, help='obtuse angle in the triangle')\n",
    "\n",
    "\n",
    "argparser.add_argument('--cosine', action='store_true', default=False, help='use cosine learning rate')\n",
    "\n",
    "argparser.add_argument('-e','--predict-e', action='store_true', default=False, help='predict epsilon')\n",
    "\n",
    "\n",
    "argparser.add_argument('--test-samples', type=int, default=1000, help='set the number of the test samples')\n",
    "argparser.add_argument('--noise-taken-per-sample', type=int, default=64, help='set the number of the noise samples taken per test sample')\n",
    "argparser.add_argument('--pca-dims', type=int, default=-1, help='number of PCA dims to reduce to')\n",
    "\n",
    "argparser.add_argument('--cheat-init', action='store_true', default=False, help='initializae the network with direction of the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a53e23b-ed43-4f53-845f-ebf62a75a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"-E 200000 -s 0.05 --wd 1E-8 -n 1024 --noise-taken-per-sample 4096 -b 4096 --lr 1E-5 --pca-dims -1 -D 6 --misc\"\n",
    "args = argparser.parse_args(txt.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602f1644-6181-45ee-8d73-ce77be3414fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looking at triangles...:   0%|                                                                                                    | 3/10000 [00:13<12:02:42,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree1:  tensor(95.1353, device='cuda:6')\n",
      "TwoLayer(\n",
      "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=784, bias=True)\n",
      "  (unreg_linear): Linear(in_features=784, out_features=784, bias=False)\n",
      ")\n",
      "number of trainable parameters: 2222096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "\n",
    "#set the device\n",
    "device = torch.device(\"cuda:\"+str(args.device) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#set the input data\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "ds = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "success = False\n",
    "for i in tqdm(range(10000), desc='Looking at triangles...'):\n",
    "    try:\n",
    "        X , idx1, idx2  = create_mnist_datapoints(ds, classes = [0], mindeg=95, maxdeg=180)\n",
    "        Xsharp , _, _  = create_mnist_datapoints(ds, classes = [0], mindeg=0, maxdeg=85, idx1_fixed=idx1, idx2_fixed=idx2)\n",
    "        success = True\n",
    "    except ValueError:\n",
    "        success = False\n",
    "    if success:\n",
    "        break\n",
    "\n",
    "X, pca_V = getPCA(X, args.pca_dims)\n",
    "X = X.to(device)\n",
    "\n",
    "X = X - X.mean(dim=0)\n",
    "\n",
    "v0 = X[1] - X[0]\n",
    "v1 = X[2] - X[0]\n",
    "\n",
    "deg = torch.arccos(torch.sum(v0*v1)/torch.sqrt(torch.sum(v0*v0)*torch.sum(v1*v1)))*180/np.pi\n",
    "print(\"degree1: \", deg)\n",
    "\n",
    "\n",
    "##run(args, X, deg, v0, v1, device)\n",
    "    \n",
    "    \n",
    "input_size = X.shape[1]\n",
    "\n",
    "model = TwoLayer(input_size, args.hidden_size).to(device)\n",
    "\n",
    "\n",
    "if args.cheat_init:\n",
    "    p = model.fc1.weight\n",
    "\n",
    "    a = torch.randn(p.shape[0])\n",
    "    b = torch.randn(p.shape[0])\n",
    "\n",
    "    ## move p.data to the projection on the plane spanned by v0 and v1\n",
    "    u0 = v0 / torch.norm(v0)\n",
    "    u1 = v1 - torch.sum(v1*u0)*u0\n",
    "    u1 = u1 / torch.norm(u1)\n",
    "    u0 = u0.view(-1,1)\n",
    "    u1 = u1.view(-1,1)\n",
    "    p.data = torch.sum(p.data @ u0, dim=1, keepdims = True) @ u0.t() + torch.sum(p.data @ u1, dim=1, keepdims = True) @ u1.t()\n",
    "\n",
    "\n",
    "model2 = None\n",
    "print(model)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(f\"number of trainable parameters: {num_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c9f0f-407c-4f26-9249-cb4bf45116b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree2:  tensor(73.1624, device='cuda:6')\n",
      "TwoLayer(\n",
      "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=784, bias=True)\n",
      "  (unreg_linear): Linear(in_features=784, out_features=784, bias=False)\n",
      ")\n",
      "number of trainable parameters: 2222096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  19%|██████████████████▎                                                                               | 37347/200000 [02:55<12:40, 213.83it/s, loss=1.27e-8]"
     ]
    }
   ],
   "source": [
    "Xsharp, pca_V = getPCA(Xsharp, args.pca_dims)\n",
    "Xsharp = Xsharp.to(device)\n",
    "\n",
    "Xsharp = Xsharp - Xsharp.mean(dim=0)\n",
    "\n",
    "\n",
    "v0_sharp = Xsharp[1] - Xsharp[0]\n",
    "v1_sharp = Xsharp[2] - Xsharp[0]\n",
    "\n",
    "deg_sharp = torch.arccos(torch.sum(v0_sharp*v1_sharp)/torch.sqrt(torch.sum(v0_sharp*v0_sharp)*torch.sum(v1_sharp*v1_sharp)))*180/np.pi\n",
    "print(\"degree2: \", deg_sharp)\n",
    "\n",
    "input_size = X.shape[1]\n",
    "\n",
    "model = TwoLayer(input_size, args.hidden_size).to(device)\n",
    "\n",
    "\n",
    "if args.cheat_init:\n",
    "    p = model.fc1.weight\n",
    "\n",
    "    a = torch.randn(p.shape[0])\n",
    "    b = torch.randn(p.shape[0])\n",
    "\n",
    "    ## move p.data to the projection on the plane spanned by v0 and v1\n",
    "    u0 = v0 / torch.norm(v0)\n",
    "    u1 = v1 - torch.sum(v1*u0)*u0\n",
    "    u1 = u1 / torch.norm(u1)\n",
    "    u0 = u0.view(-1,1)\n",
    "    u1 = u1.view(-1,1)\n",
    "    p.data = torch.sum(p.data @ u0, dim=1, keepdims = True) @ u0.t() + torch.sum(p.data @ u1, dim=1, keepdims = True) @ u1.t()\n",
    "\n",
    "\n",
    "model2 = None\n",
    "print(model)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(f\"number of trainable parameters: {num_params}\\n\")\n",
    "\n",
    "\n",
    "# add weight decay to non-bias weights\n",
    "paramlist = add_weight_decay(model, weight_decay=args.wd, skip_list = (\"unreg_linear.weight\",)) #1e-5\n",
    "optimizer = torch.optim.Adam(paramlist, lr=args.lr)\n",
    "##optimizer = torch.optim.SGD(paramlist, lr=args.lr)\n",
    "\n",
    "\n",
    "if args.cosine:\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=0.0)\n",
    "\n",
    "#set the loss function\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "#set the wandb\n",
    "if not args.misc:\n",
    "    wandb.init(project=\"phased_denoiser\", entity='dl-projects' ,  config=args)\n",
    "    ##wandb.watch(model, log=\"all\")\n",
    "\n",
    "\n",
    "##create a data loader from the data points:\n",
    "\n",
    "#set the training loop\n",
    "\n",
    "\n",
    "\n",
    "repeats = (3+args.batch_size-1)//3\n",
    "\n",
    "bar = tqdm( range(args.epochs), total = args.epochs, desc=\"training\")\n",
    "\n",
    "\n",
    "reset_samples = args.noise_taken_per_sample // repeats\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "init_state = torch.random.get_rng_state()\n",
    "\n",
    "noise_state = init_state\n",
    "\n",
    "decreased = False\n",
    "\n",
    "for epoch in bar:\n",
    "\n",
    "    if args.noise_taken_per_sample > 0 and epoch % reset_samples == 0:\n",
    "        noise_state = init_state\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    x = X.repeat(repeats, 1)\n",
    "\n",
    "\n",
    "    tmp_state = torch.random.get_rng_state()\n",
    "    torch.random.set_rng_state(noise_state)\n",
    "\n",
    "    noise = torch.randn_like(x)\n",
    "    noise_state = torch.random.get_rng_state()\n",
    "    torch.random.set_rng_state(tmp_state)\n",
    "\n",
    "\n",
    "    y = x + args.sigma* noise\n",
    "\n",
    "    y = y[torch.randperm(y.shape[0])[:args.batch_size]]\n",
    "\n",
    "    y = x + args.sigma* noise\n",
    "\n",
    "\n",
    "    if args.predict_e:\n",
    "        eat = model(y)\n",
    "        loss = loss_func(eat, noise )\n",
    "    else:\n",
    "        xat = model(y)\n",
    "        loss = loss_func(xat, x)\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if args.cosine:\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    total_loss = loss.item()\n",
    "\n",
    "\n",
    "    L2 = model.fc1.weight.norm().item() + model.fc2.weight.norm().item() \n",
    "\n",
    "    # if not decreased:\n",
    "    #     if deg > 90 and L2 <= 8.1:\n",
    "    #         paramlist = add_weight_decay(model, weight_decay=args.wd/100, skip_list = (\"unreg_linear.weight\",)) #1e-5\n",
    "    #         optimizer = torch.optim.Adam(paramlist, lr=args.lr)\n",
    "    #         decreased = True\n",
    "    #     elif deg <= 90 and L2 <= 12.1:\n",
    "    #         paramlist = add_weight_decay(model, weight_decay=args.wd/100, skip_list = (\"unreg_linear.weight\",)) #1e-5\n",
    "    #         optimizer = torch.optim.Adam(paramlist, lr=args.lr)\n",
    "    #         decreased = True\n",
    "\n",
    "    if wandb.run is not None:\n",
    "        wandb.log({\"epoch\": epoch, \"loss\": total_loss, 'learning rate': optimizer.param_groups[0]['lr'], 'L2': L2})\n",
    "\n",
    "    bar.set_postfix(loss=total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba6d31-9390-4ee7-8afd-30b33877356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_theory2(X, ax, args, grid_points, grid_range, device, levels, deg):\n",
    "\n",
    "\n",
    "    x_1 = X[0]\n",
    "    x_2 = X[1] \n",
    "    x_3 = X[2]\n",
    "\n",
    "    if deg > 90:\n",
    "\n",
    "        x_2 = x_2 - x_1\n",
    "        x_3 = x_3 - x_1\n",
    "        x_1 = x_1 - x_1\n",
    "\n",
    "        center = (x_1 + x_2 + x_3)/3 \n",
    "\n",
    "        ##sigma = args.sigma * math.sqrt(x_1.shape[0])\n",
    "        sigma = args.sigma * math.sqrt(2*math.log(args.noise_taken_per_sample))\n",
    "\n",
    "        u_2 = x_2/torch.norm(x_2)\n",
    "        u_3 = x_3/torch.norm(x_3)\n",
    "\n",
    "        slope = (torch.norm(x_2))/(torch.norm(x_2)-2*sigma)\n",
    "        g_2 = lambda t: torch.where(t < sigma, torch.zeros_like(t), torch.where(t > torch.norm(x_2)-sigma, torch.norm(x_2), (t-sigma)*slope))\n",
    "\n",
    "        slope = (torch.norm(x_3))/(torch.norm(x_3)-2*sigma)\n",
    "        g_3 = lambda t: torch.where(t < sigma, torch.zeros_like(t), torch.where(t > torch.norm(x_3)-sigma, torch.norm(x_3), (t-sigma)*slope))\n",
    "\n",
    "\n",
    "        f = lambda y: u_2*g_2(torch.sum(u_2*y)) + u_3*g_3(torch.sum(u_3*y))\n",
    "\n",
    "    elif deg <= 90:\n",
    "        x_0 = (x_1 + x_2 + x_3)/3 \n",
    "\n",
    "        u_1 = x_1/torch.norm(x_1 - x_0)\n",
    "        u_2 = x_2/torch.norm(x_2 - x_0)\n",
    "        u_3 = x_3/torch.norm(x_3 - x_0)\n",
    "\n",
    "        rho = args.sigma * math.sqrt(2*math.log(args.noise_taken_per_sample))\n",
    "\n",
    "        # \\bv f^*(\\vy) = \\vu_1 \\phi_1(\\vu_1^\\T(\\vy-\\vx_0)) + \\vu_2 \\phi_2(\\vu_2^\\T(\\vy-\\vx_0)) + \\vu_3 \\phi_3(\\vu_3^\\T(\\vy-\\vx_0)) - \\vx_0\n",
    "        # where $\\vx_0 \\in \\R^d$ is the orthocenter of the triangle, \n",
    "        # and for $i=1,2,3$ we have $\\phi_i(\\vy) = s_i([t-a_i]_+-[t-b_i]_+)$ with $\\vu_i = \\frac{\\vx_i-\\vx_0}{\\|\\vx_i-\\vx_0\\|}$,\n",
    "        #  for either $\\vx_j$ with $j\\neq i$, , and \n",
    "\n",
    "        # $a_i = \\vu_i^\\T(\\vx_j-\\vx_0) + \\rho$\n",
    "\n",
    "        a_1 = torch.sum(u_1*(x_2-x_0)) + rho\n",
    "        a_2 = torch.sum(u_2*(x_3-x_0)) + rho\n",
    "        a_3 = torch.sum(u_3*(x_1-x_0)) + rho\n",
    "        # $b_i = \\|\\vx_i-\\vx_0\\|-\\rho$\n",
    "        b_1 = torch.norm(x_1-x_0) - rho\n",
    "        b_2 = torch.norm(x_2-x_0) - rho\n",
    "        b_3 = torch.norm(x_3-x_0) - rho\n",
    "\n",
    "        # $s_i = \\|\\vx_i-\\vx_0\\|/(b_i-a_i)$.\n",
    "        slope1 = torch.norm(x_1-x_0)/(b_1-a_1)\n",
    "        slope2 = torch.norm(x_2-x_0)/(b_2-a_2)\n",
    "        slope3 = torch.norm(x_3-x_0)/(b_3-a_3)\n",
    "        ##breakpoint()\n",
    "\n",
    "        phi_1 = lambda t: torch.where(t < a_1, torch.zeros_like(t), torch.where(t > b_1, torch.norm(x_1-x_0), (t-a_1)*slope1))\n",
    "        phi_2 = lambda t: torch.where(t < a_2, torch.zeros_like(t), torch.where(t > b_2, torch.norm(x_2-x_0), (t-a_2)*slope2))\n",
    "        phi_3 = lambda t: torch.where(t < a_3, torch.zeros_like(t), torch.where(t > b_3, torch.norm(x_3-x_0), (t-a_3)*slope3))\n",
    "\n",
    "        f = lambda y: u_1*phi_1(torch.sum(u_1*(y-x_0))) + u_2*phi_2(torch.sum(u_2*(y-x_0))) + u_3*phi_3(torch.sum(u_3*(y-x_0))) + x_0\n",
    "        center = 0\n",
    "\n",
    "    v0 = x_2 - x_1\n",
    "    v1 = x_3 - x_1\n",
    "    u0 = v0 / v0.norm()\n",
    "    u1 = v1 - torch.dot(u0, v1)*u0\n",
    "    ##u1 = v1\n",
    "    u1 = u1 / u1.norm()\n",
    "\n",
    "\n",
    "    gridvals = torch.linspace(-grid_range, grid_range, grid_points, device=device)\n",
    "\n",
    "    X0 = torch.zeros((grid_points, grid_points))\n",
    "    X1 = torch.zeros((grid_points, grid_points))\n",
    "    X_orth = torch.zeros(grid_points, grid_points)\n",
    "\n",
    "\n",
    "\n",
    "    Y = torch.zeros((2, grid_points, grid_points))\n",
    "\n",
    "    for i, a1 in tqdm(enumerate(gridvals), total = grid_points):\n",
    "        for j, a2 in enumerate(gridvals):\n",
    "            ##y = a1*v0 + a2*v1 \n",
    "            y = a1*u0*v1.norm() + a2*u1*v2.norm()\n",
    "\n",
    "            xhat = f(y.view(1, -1) + center ) - center\n",
    "            \n",
    "            x0, x1 ,x_orth = project(xhat , u0, u1)\n",
    "            \n",
    "            X0[i,j]=x0.item()\n",
    "            X1[i,j]=x1.item()\n",
    "            X_orth[i,j]=x_orth.item()\n",
    "            Y[0,i,j], Y[1,i,j], _ = project(y , u0, u1)\n",
    "\n",
    "    X0 = X0.cpu().numpy()\n",
    "    X1 = X1.cpu().numpy()\n",
    "    X_orth = X_orth.cpu().numpy()\n",
    "\n",
    "    ax[0].set_title(\"Theory- Direction 0\", fontsize=18)\n",
    "    ax[0].contourf(Y[0], Y[1],X0, levels = levels)\n",
    "\n",
    "    ax[1].set_title(\"Direction 1\")\n",
    "    ax[1].contourf(Y[0], Y[1],X1, levels = levels)\n",
    "    \n",
    "    ##ax[2].set_title(\"Orthogonal Direction\")\n",
    "    ##ax[2].contourf(Y[0], Y[1],X_orth, levels = levels)\n",
    "\n",
    "\n",
    "def display2(model, model2, device, args, deg, v0, v1, X, noise_state,  grid_range =3 , grid_points = 100):\n",
    "\n",
    "    gridvals = torch.linspace(-grid_range, grid_range, grid_points, device=device)\n",
    "\n",
    "    u0 = v0 / v0.norm()\n",
    "    u1 = v1 - torch.dot(u0, v1)*u0\n",
    "    ##u1 = v1\n",
    "    u1 = u1 / u1.norm()\n",
    "\n",
    "    X0 = torch.zeros(grid_points, grid_points)\n",
    "    X1 = torch.zeros(grid_points, grid_points)\n",
    "    X_orth = torch.zeros(grid_points, grid_points)\n",
    "\n",
    "    Y = torch.zeros((2, grid_points, grid_points))\n",
    "\n",
    "    for i, a1 in tqdm(enumerate(gridvals), total = grid_points):\n",
    "        for j, a2 in enumerate(gridvals):\n",
    "            y = a1*u0*v1.norm() + a2*u1*v2.norm()\n",
    "            \n",
    "            xhat = model(y)\n",
    "            \n",
    "            x0, x1 ,x_orth = project(xhat, u0, u1)\n",
    "            \n",
    "            X0[i,j]=x0.item()\n",
    "            X1[i,j]=x1.item()\n",
    "            X_orth[i,j]=x_orth.item()\n",
    "            Y[0,i,j], Y[1,i,j], _ = project(y, u0, u1)\n",
    "\n",
    "    v0_norm = v0.norm().cpu().item()\n",
    "    v1_norm = v1.norm().cpu().item()\n",
    "    ##Y = np.asarray(np.meshgrid(gridvals.cpu().numpy()*v0_norm , gridvals.cpu().numpy()*v1_norm))\n",
    "\n",
    "    ##Y = -Y\n",
    "\n",
    "    X0 = X0.cpu().numpy()\n",
    "    X1 = X1.cpu().numpy()\n",
    "    X_orth = X_orth.cpu().numpy()\n",
    "\n",
    "\n",
    "    maxval = np.max(X0)\n",
    "    maxval = np.maximum(np.max(X1), maxval)\n",
    "\n",
    "    minval = np.min(X0)\n",
    "    minval = np.minimum(np.min(X1), minval)\n",
    "\n",
    "\n",
    "\n",
    "    levels = np.linspace(-3, 3, 31)\n",
    "\n",
    "    fig, ax_all = plt.subplots(2,2,  figsize=(8,12),sharex='col', sharey='row', layout='constrained')\n",
    "\n",
    "    ax = ax_all[:,0]\n",
    "    axb = ax_all[:,1]\n",
    "\n",
    "\n",
    "    ax[0].set_title(\"Results- Direction 0\")\n",
    "    CS = ax[0].contourf(Y[0], Y[1],X0, levels = levels )\n",
    "    plot_points(X, u0, u1, v0, v1, ax[0], sigma = args.sigma, noise_state = noise_state, N=args.noise_taken_per_sample)\n",
    "\n",
    "\n",
    "\n",
    "    # Add the contour line levels to the colorbar\n",
    "\n",
    "    # plt.figure()\n",
    "\n",
    "    ax[1].set_title(\"Direction 1\")\n",
    "    ax[1].contourf(Y[0], Y[1],X1, levels = levels)\n",
    "    plot_points(X, u0, u1, v0, v1, ax[1], sigma = args.sigma, noise_state = noise_state, N=args.noise_taken_per_sample)\n",
    "\n",
    "    # plt.figure()\n",
    "\n",
    "    ##ax[2].set_title(\"Orthogonal Direction\")\n",
    "    ##ax[2].contourf(Y[0], Y[1],X_orth, levels = levels)\n",
    "    ##plot_points(X, u0, u1, v0, v1, ax[2], sigma = args.sigma, noise_state = noise_state, N=args.noise_taken_per_sample)\n",
    "\n",
    "\n",
    "    plot_theory2(X, axb, args, grid_points, grid_range, device, levels, deg)\n",
    "\n",
    "    plot_points(X, u0, u1, v0, v1, axb[0], sigma = args.sigma, noise_state = noise_state, N=args.noise_taken_per_sample)\n",
    "    plot_points(X, u0, u1, v0, v1, axb[1], sigma = args.sigma, noise_state = noise_state, N=args.noise_taken_per_sample)\n",
    "    ##plot_points(X, u0, u1, v0, v1, axb[2], sigma = args.sigma, noise_state = noise_state, N=args.noise_taken_per_sample)\n",
    "\n",
    "    # plt.figure()\n",
    "\n",
    "    plt.colorbar(CS, ax=axb)\n",
    "\n",
    "    wd_log = np.log10(args.wd) if args.wd > 0 else -6\n",
    "    wd_log = -np.round(wd_log)\n",
    "    plt.savefig(f\"figures/contour_deg_{int(np.round(deg.cpu()))}_D{args.pca_dims}_E{args.epochs}_wd{wd_log}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
